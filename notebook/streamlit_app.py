# streamlit_app.py
import streamlit as st
import pandas as pd
import pickle
import jieba
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
import os
import sys

# å¯¼å…¥ä¸­æ–‡å­—ä½“é…ç½®
sys.path.append('.')
from matplotlib_config import configure_matplotlib

# é…ç½®matplotlibä¸­æ–‡å­—ä½“
configure_matplotlib()

# å¤šè¯­è¨€æ–‡æœ¬é…ç½®
TEXTS = {
    "zh": {
        "title": "ğŸ˜Š ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æç³»ç»Ÿ",
        "project_info": "â„¹ï¸ é¡¹ç›®ä¿¡æ¯",
        "project_overview": "**é¡¹ç›®æ¦‚è¿°**\n- åŸºäºæœºå™¨å­¦ä¹ çš„ä¸­æ–‡ç¤¾äº¤åª’ä½“æ–‡æœ¬æƒ…æ„Ÿåˆ†æ\n- ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹ï¼Œåœ¨å¾®åšæ•°æ®é›†ä¸Šè®­ç»ƒ\n- F1åˆ†æ•°ï¼šçº¦ 0.70",
        "tech_stack": "**æŠ€æœ¯æ ˆ**\n- æ•°æ®å¤„ç†ï¼šPandas, NumPy\n- NLPå·¥å…·ï¼šJieba (ä¸­æ–‡åˆ†è¯)\n- ç‰¹å¾å·¥ç¨‹ï¼šTF-IDF\n- æœºå™¨å­¦ä¹ ï¼šScikit-learn\n- å¯è§†åŒ–ï¼šMatplotlib, Seaborn\n- éƒ¨ç½²å±•ç¤ºï¼šStreamlit",
        "analysis_title": "ğŸ” å®æ—¶æƒ…æ„Ÿåˆ†æ",
        "input_placeholder": "ä¾‹å¦‚ï¼šè¿™éƒ¨ç”µå½±çœŸçš„å¾ˆæ£’ï¼Œæ¼”å‘˜æ¼”æŠ€åœ¨çº¿ï¼Œå‰§æƒ…æ‰£äººå¿ƒå¼¦ï¼",
        "analyze_button": "å¼€å§‹åˆ†æ",
        "analyzing": "æ­£åœ¨åˆ†ææƒ…æ„Ÿ...",
        "result_title": "åˆ†æç»“æœ",
        "sentiment": "æƒ…æ„Ÿå€¾å‘",
        "confidence": "ç½®ä¿¡åº¦",
        "probability_dist": "æƒ…æ„Ÿé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ",
        "view_details": "æŸ¥çœ‹æ–‡æœ¬å¤„ç†è¿‡ç¨‹",
        "original_text": "**åŸå§‹æ–‡æœ¬ï¼š**",
        "cleaned_text": "**æ¸…æ´—åæ–‡æœ¬ï¼š**",
        "segmented_text": "**åˆ†è¯ç»“æœï¼š**",
        "overview_title": "ğŸ“Š é¡¹ç›®æ¦‚è§ˆä¸æ€§èƒ½",
        "performance": "æ¨¡å‹æ€§èƒ½æŒ‡æ ‡",
        "data_size": "æ•°æ®é‡",
        "model_comparison": "æ¨¡å‹å¯¹æ¯”åˆ†æ",
        "highlights_title": "âœ¨ é¡¹ç›®äº®ç‚¹",
        "highlights": "- âœ… **å®Œæ•´æµç¨‹**ï¼šä»æ•°æ®æ¸…æ´—åˆ°æ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹å®ç°\n- âœ… **ä¸­æ–‡ä¼˜åŒ–**ï¼šé’ˆå¯¹å¾®åšæ–‡æœ¬çš„ç‰¹æ®Šæ¸…æ´—å’Œåˆ†è¯å¤„ç†\n- âœ… **æ·±å…¥åˆ†æ**ï¼šå¯¹æ¯”å¤šç§æ¨¡å‹ï¼Œå¾—å‡ºå…³é”®æŠ€æœ¯æ´è§\n- âœ… **äº¤äº’å±•ç¤º**ï¼šå®æ—¶æƒ…æ„Ÿåˆ†æï¼Œç›´è§‚å‘ˆç°ç»“æœ\n- âœ… **æŠ€æœ¯æ¢ç´¢**ï¼šå°è¯•Sparkå¤§æ•°æ®å¤„ç†æ¡†æ¶",
        "summary_title": "ğŸ“‹ æŠ€æœ¯æ€»ç»“ä¸å±•æœ›",
        "implementation": "æŠ€æœ¯å®ç°",
        "implementation_details": "1. **æ•°æ®è·å–**ï¼šä½¿ç”¨WeiboSenti100Kå…¬å¼€æ•°æ®é›†\n2. **æ•°æ®é¢„å¤„ç†**ï¼šæ–‡æœ¬æ¸…æ´—ã€ä¸­æ–‡åˆ†è¯ã€åœç”¨è¯è¿‡æ»¤\n3. **ç‰¹å¾å·¥ç¨‹**ï¼šTF-IDFæ–‡æœ¬å‘é‡åŒ–ï¼ˆ2000ç»´ç‰¹å¾ï¼‰\n4. **æ¨¡å‹è®­ç»ƒ**ï¼šé€»è¾‘å›å½’ã€éšæœºæ£®æ—ã€XGBoostå¯¹æ¯”\n5. **æ¨¡å‹è°ƒä¼˜**ï¼šç½‘æ ¼æœç´¢ä¼˜åŒ–è¶…å‚æ•°\n6. **ç»“æœè¯„ä¼°**ï¼šå‡†ç¡®ç‡ã€F1åˆ†æ•°ç­‰å¤šç»´åº¦è¯„ä¼°",
        "future_work": "æœªæ¥ä¼˜åŒ–æ–¹å‘",
        "future_details": "1. **ç‰¹å¾ä¼˜åŒ–**ï¼šå°è¯•è¯å‘é‡ã€BERTç­‰æ·±åº¦å­¦ä¹ ç‰¹å¾\n2. **æ¨¡å‹å‡çº§**ï¼šä½¿ç”¨Transformeræ¨¡å‹æå‡å‡†ç¡®ç‡\n3. **æ•°æ®æ‰©å±•**ï¼šçˆ¬å–å®æ—¶å¾®åšæ•°æ®ï¼Œå¢åŠ æ•°æ®å¤šæ ·æ€§\n4. **éƒ¨ç½²ä¼˜åŒ–**ï¼šä½¿ç”¨Dockerå®¹å™¨åŒ–ï¼Œäº‘æœåŠ¡å™¨éƒ¨ç½²\n5. **åŠŸèƒ½æ‰©å±•**ï¼šæƒ…æ„ŸåŸå› åˆ†æã€ä¸»é¢˜æŒ–æ˜ç­‰",
        "run_instructions": "ğŸƒ å¦‚ä½•è¿è¡Œæ­¤åº”ç”¨",
        "installation": "**å®‰è£…ä¾èµ–ï¼š**",
        "run_command": "**è¿è¡Œåº”ç”¨ï¼š**",
        "requirements": "**ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨ï¼š**",
        "model_not_found": "æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ã€‚è¯·ç¡®ä¿å·²è¿è¡Œæ¨¡å‹è®­ç»ƒè„šæœ¬ã€‚",
        "no_text_warning": "è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬ã€‚",
        "positive": "æ­£é¢ ğŸ˜Š",
        "negative": "è´Ÿé¢ ğŸ˜”",
        "chart_generating": "é¡¹ç›®æ€§èƒ½å›¾è¡¨ç”Ÿæˆä¸­...",
        "chart_failed": "å›¾è¡¨åŠ è½½å¤±è´¥"
    },
    "en": {
        "title": "ğŸ˜Š Social Media Sentiment Analysis System",
        "project_info": "â„¹ï¸ Project Information",
        "project_overview": "**Project Overview**\n- Machine learning based Chinese social media text sentiment analysis\n- Using logistic regression model trained on Weibo dataset\n- F1 Score: ~0.70",
        "tech_stack": "**Technology Stack**\n- Data Processing: Pandas, NumPy\n- NLP Tool: Jieba (Chinese word segmentation)\n- Feature Engineering: TF-IDF\n- Machine Learning: Scikit-learn\n- Visualization: Matplotlib, Seaborn\n- Deployment: Streamlit",
        "analysis_title": "ğŸ” Real-time Sentiment Analysis",
        "input_placeholder": "e.g., This movie is really great, the acting is superb, and the plot is captivating!",
        "analyze_button": "Analyze Sentiment",
        "analyzing": "Analyzing sentiment...",
        "result_title": "Analysis Results",
        "sentiment": "Sentiment",
        "confidence": "Confidence",
        "probability_dist": "Sentiment Prediction Probability Distribution",
        "view_details": "View Text Processing Details",
        "original_text": "**Original Text:**",
        "cleaned_text": "**Cleaned Text:**",
        "segmented_text": "**Segmented Text:**",
        "overview_title": "ğŸ“Š Project Overview & Performance",
        "performance": "Model Performance Metrics",
        "data_size": "Data Size",
        "model_comparison": "Model Comparison Analysis",
        "highlights_title": "âœ¨ Project Highlights",
        "highlights": "- âœ… **Complete Pipeline**: Full implementation from data cleaning to model deployment\n- âœ… **Chinese Optimization**: Specialized cleaning and segmentation for Weibo text\n- âœ… **In-depth Analysis**: Comparison of multiple models with key insights\n- âœ… **Interactive Display**: Real-time sentiment analysis with intuitive results\n- âœ… **Technical Exploration**: Attempted Spark big data processing (environment issues documented)",
        "summary_title": "ğŸ“‹ Technical Summary & Future Work",
        "implementation": "Technical Implementation",
        "implementation_details": "1. **Data Acquisition**: WeiboSenti100K public dataset\n2. **Data Preprocessing**: Text cleaning, Chinese word segmentation, stop word filtering\n3. **Feature Engineering**: TF-IDF text vectorization (2000 features)\n4. **Model Training**: Comparison of Logistic Regression, Random Forest, XGBoost\n5. **Model Tuning**: Hyperparameter optimization via grid search\n6. **Evaluation**: Multi-dimensional evaluation with accuracy, F1 score, etc.",
        "future_work": "Future Optimization Directions",
        "future_details": "1. **Feature Optimization**: Try word embeddings, BERT, and deep learning features\n2. **Model Upgrade**: Use Transformer models to improve accuracy\n3. **Data Expansion**: Crawl real-time Weibo data for diversity\n4. **Deployment Optimization**: Docker containerization and cloud server deployment\n5. **Feature Expansion**: Sentiment reason analysis, topic mining, etc.",
        "run_instructions": "ğŸƒ How to Run This Application",
        "installation": "**Install Dependencies:**",
        "run_command": "**Run Application:**",
        "requirements": "**Ensure these files exist:**",
        "model_not_found": "Model file not found. Please ensure you have run the model training script.",
        "no_text_warning": "Please enter text to analyze.",
        "positive": "Positive ğŸ˜Š",
        "negative": "Negative ğŸ˜”",
        "chart_generating": "Generating performance chart...",
        "chart_failed": "Chart loading failed"
    }
}

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title="Social Media Sentiment Analysis System",
    page_icon="ğŸ˜Š",
    layout="wide"
)

# åˆå§‹åŒ–è¯­è¨€é€‰æ‹©
if 'language' not in st.session_state:
    st.session_state.language = 'zh'

# ä¾§è¾¹æ  - è¯­è¨€é€‰æ‹©
with st.sidebar:
    # è¯­è¨€åˆ‡æ¢æŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ä¸­æ–‡", use_container_width=True):
            st.session_state.language = 'zh'
            st.rerun()
    with col2:
        if st.button("English", use_container_width=True):
            st.session_state.language = 'en'
            st.rerun()
    
    # ä½¿ç”¨å½“å‰è¯­è¨€è·å–æ–‡æœ¬
    t = TEXTS[st.session_state.language]
    
    st.header(t["project_info"])
    st.markdown(t["project_overview"])
    st.markdown(t["tech_stack"])
    
    st.markdown("---")
    st.caption("Project Duration: 5 days")
    st.caption("Data Scale: 119,988 labeled Weibo posts")

# åŠ è½½æ¨¡å‹å’Œå‘é‡åŒ–å™¨
@st.cache_resource
def load_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œå‘é‡åŒ–å™¨"""
    try:
        model_path = './data/pandas_processed/best_sentiment_model.pkl'
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        return model_data['model'], model_data['vectorizer']
    except FileNotFoundError:
        st.error(TEXTS[st.session_state.language]["model_not_found"])
        return None, None

model, vectorizer = load_model()

# æ–‡æœ¬æ¸…æ´—å‡½æ•°
def clean_weibo_text(text):
    if not isinstance(text, str):
        return ""
    text = re.sub(r'https?://\S+', '', text)
    text = re.sub(r'@[\w\u4e00-\u9fa5]+', '', text)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'[^\w\u4e00-\u9fa5ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š\"\'\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# åˆ†è¯å‡½æ•°
def jieba_cut(text):
    return ' '.join(jieba.cut(text))

# è·å–å½“å‰è¯­è¨€çš„æ–‡æœ¬
t = TEXTS[st.session_state.language]

# åº”ç”¨æ ‡é¢˜
st.title(t["title"])
st.markdown("---")

# ä¸»ç•Œé¢åˆ†ä¸ºä¸¤åˆ—
col1, col2 = st.columns([1, 1])

with col1:
    st.header(t["analysis_title"])
    
    # æ–‡æœ¬è¾“å…¥åŒº
    user_input = st.text_area(
        "è¯·è¾“å…¥è¦åˆ†æçš„ä¸­æ–‡æ–‡æœ¬ï¼š" if st.session_state.language == 'zh' else "Enter Chinese text to analyze:",
        height=150,
        placeholder=t["input_placeholder"],
        help="æ”¯æŒå¾®åšã€è¯„è®ºã€çŸ­æ–‡æœ¬ç­‰ä¸­æ–‡å†…å®¹" if st.session_state.language == 'zh' else "Supports Chinese content like Weibo, comments, short texts"
    )
    
    # åˆ†ææŒ‰é’®
    if st.button(t["analyze_button"], type="primary", use_container_width=True):
        if user_input.strip():
            with st.spinner(t["analyzing"]):
                # 1. æ¸…æ´—æ–‡æœ¬
                cleaned_text = clean_weibo_text(user_input)
                
                # 2. åˆ†è¯
                segmented_text = jieba_cut(cleaned_text)
                
                # 3. è½¬æ¢ä¸ºTF-IDFç‰¹å¾
                if vectorizer and model:
                    features = vectorizer.transform([segmented_text])
                    
                    # 4. é¢„æµ‹
                    prediction = model.predict(features)[0]
                    probability = model.predict_proba(features)[0]
                    
                    # 5. æ˜¾ç¤ºç»“æœ
                    sentiment = t["positive"] if prediction == 1 else t["negative"]
                    confidence = probability[1] if prediction == 1 else probability[0]
                    
                    # ç»“æœå±•ç¤ºå¡ç‰‡
                    st.markdown(f"### {t['result_title']}")
                    
                    result_col1, result_col2 = st.columns(2)
                    
                    with result_col1:
                        st.metric(t["sentiment"], sentiment)
                    
                    with result_col2:
                        st.metric(t["confidence"], f"{confidence:.2%}")
                    
                    # æ¦‚ç‡å¯è§†åŒ–
                    fig, ax = plt.subplots(figsize=(8, 4))
                    
                    # æ ¹æ®è¯­è¨€è®¾ç½®æ ‡ç­¾
                    if st.session_state.language == 'zh':
                        sentiments = ['è´Ÿé¢', 'æ­£é¢']
                    else:
                        sentiments = ['Negative', 'Positive']
                        
                    colors = ['#FF6B6B', '#4ECDC4']
                    bars = ax.bar(sentiments, probability, color=colors, alpha=0.8)
                    
                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, prob in zip(bars, probability):
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                               f'{prob:.2%}', ha='center', va='bottom')
                    
                    ax.set_ylabel('Probability' if st.session_state.language == 'en' else 'æ¦‚ç‡')
                    ax.set_ylim([0, 1.1])
                    ax.set_title(t["probability_dist"])
                    st.pyplot(fig)
                    
                    # æ˜¾ç¤ºå¤„ç†åçš„æ–‡æœ¬
                    with st.expander(t["view_details"]):
                        st.write(t["original_text"], user_input)
                        st.write(t["cleaned_text"], cleaned_text)
                        st.write(t["segmented_text"], segmented_text)
                else:
                    st.error("Model failed to load, cannot perform analysis." if st.session_state.language == 'en' else "æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
        else:
            st.warning(t["no_text_warning"])

with col2:
    st.header(t["overview_title"])
    
    # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½
    st.subheader(t["performance"])
    
    # åˆ›å»ºæŒ‡æ ‡å¡ç‰‡
    metric_col1, metric_col2, metric_col3 = st.columns(3)
    
    with metric_col1:
        st.metric("F1 Score" if st.session_state.language == 'en' else "F1åˆ†æ•°", "0.70")
    
    with metric_col2:
        st.metric("Accuracy" if st.session_state.language == 'en' else "å‡†ç¡®ç‡", "0.70")
    
    with metric_col3:
        st.metric(t["data_size"], "119,988")
    
    # å°è¯•åŠ è½½å¹¶æ˜¾ç¤ºç”Ÿæˆçš„å›¾è¡¨
    st.subheader(t["model_comparison"])
    
    try:
        # å°è¯•åŠ è½½ä¹‹å‰ç”Ÿæˆçš„å›¾è¡¨
        chart_path = './data/pandas_processed/advanced_model_comparison.png'
        if os.path.exists(chart_path):
            st.image(chart_path, 
                    caption="Different ML Model Performance Comparison" if st.session_state.language == 'en' 
                    else "ä¸åŒæœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        else:
            # å¦‚æœå›¾è¡¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹å›¾
            st.info(t["chart_generating"])
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # æ ¹æ®è¯­è¨€è®¾ç½®æ¨¡å‹åç§°
            if st.session_state.language == 'zh':
                models = ['é€»è¾‘å›å½’', 'éšæœºæ£®æ—', 'XGBoost']
            else:
                models = ['Logistic Regression', 'Random Forest', 'XGBoost']
                
            f1_scores = [0.70, 0.67, 0.61]
            colors = ['#4ECDC4', '#FF6B6B', '#FFE66D']
            
            bars = ax.bar(models, f1_scores, color=colors, alpha=0.8)
            ax.set_ylabel('F1 Score' if st.session_state.language == 'en' else 'F1åˆ†æ•°')
            ax.set_ylim([0.5, 0.75])
            
            title = 'Model Performance Comparison (F1 Score)' if st.session_state.language == 'en' else 'æ¨¡å‹æ€§èƒ½å¯¹æ¯” (F1åˆ†æ•°)'
            ax.set_title(title)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, score in zip(bars, f1_scores):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                       f'{score:.3f}', ha='center', va='bottom')
            
            st.pyplot(fig)
    except Exception as e:
        st.warning(f"{t['chart_failed']}: {str(e)}")
    
    # é¡¹ç›®äº®ç‚¹
    st.subheader(t["highlights_title"])
    st.markdown(t["highlights"])

# åº•éƒ¨çš„é¡¹ç›®æ€»ç»“
st.markdown("---")
st.header(t["summary_title"])

summary_col1, summary_col2 = st.columns(2)

with summary_col1:
    st.subheader(t["implementation"])
    st.markdown(t["implementation_details"])

with summary_col2:
    st.subheader(t["future_work"])
    st.markdown(t["future_details"])

# è¿è¡Œè¯´æ˜
with st.expander(t["run_instructions"]):
    st.markdown(f"""
    **{t['installation']}**
    ```bash
    pip install streamlit pandas scikit-learn jieba matplotlib seaborn
    ```
    
    **{t['run_command']}**
    ```bash
    streamlit run streamlit_app.py
    ```
    
    **{t['requirements']}**
    - `./data/pandas_processed/best_sentiment_model.pkl` (Trained model)
    - `./data/pandas_processed/advanced_model_comparison.png` (Performance comparison chart, optional)
    """)

st.markdown("---")
if st.session_state.language == 'zh':
    st.caption("Â© 2024 ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æé¡¹ç›® | åŸºäºPythonçš„æ•°æ®ç§‘å­¦ä½œå“é›†")
else:
    st.caption("Â© 2024 Social Media Sentiment Analysis Project | Python Data Science Portfolio")